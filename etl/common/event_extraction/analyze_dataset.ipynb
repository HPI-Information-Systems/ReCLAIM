{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "This notebook explains how you can analyze a dataset regarding provenance descriptions and how to find good few-shot examples. This example is for the \"Wiesbaden Central Collection Point\" dataset but can be used as reference for every dataset. See the README in this directory to get an overview of the current state in event extraction. For generating embeddings and running the prompt, you need to set your API key. We recommend to play around with batch sizes and to use techniques for minimizing prompt tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Setup\n",
    "We recommend to use the default paths defined here for each data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  history-and-ownership  \\\n",
      "0     Deposited in Kaiseroda Mine (erkers) or Ransba...   \n",
      "1     Deposited in Kaiseroda Mine (erkers) or Ransba...   \n",
      "2     Deposited in Kaiseroda Mine (Merkers) or Ransb...   \n",
      "3     Deposited in Kaiserroda Mine (erkers) or Ransb...   \n",
      "4     Deposited in Kaiseroda Mine (Merkers) or Ransb...   \n",
      "...                                                 ...   \n",
      "6286                                               None   \n",
      "6287                                               None   \n",
      "6288                                               None   \n",
      "6289                                               None   \n",
      "6290  Brou ht in from Frankfurt Bunker, demanded bec...   \n",
      "\n",
      "                    depot-possessor depot-number  \\\n",
      "0                              None         None   \n",
      "1                              None   Case GG 91   \n",
      "2                              None    Case GG 9   \n",
      "3                        Cave G-G g            9   \n",
      "4                     Case G₁ G 127         None   \n",
      "...                             ...          ...   \n",
      "6286  Generallandesarchiv Karlsruhe         None   \n",
      "6287             JRSON, Frankfurt/M   Depot Cat.   \n",
      "6288                           Ther         None   \n",
      "6289                           None         None   \n",
      "6290           Hess State/Frankfurt       Bunker   \n",
      "\n",
      "                            condition-and-repair-record  \\\n",
      "0     Received by J.V.Danzas 1931 17: 1:48. Tafel ge...   \n",
      "1     4 old, long vertical cracks that have been res...   \n",
      "2                                Panel slightly warped.   \n",
      "3                           Old repaired split at left.   \n",
      "4            Many small blisters on coat. Panel warped.   \n",
      "...                                                 ...   \n",
      "6286                                               None   \n",
      "6287                                               None   \n",
      "6288                                               None   \n",
      "6289                                               None   \n",
      "6290                                               None   \n",
      "\n",
      "                                      arrival-condition      arrival-date  \\\n",
      "0                                                  good      Aug-Sep 1945   \n",
      "1                                        Fair undamaged       Aug-Sept 45   \n",
      "2                                 Good slightly damaged       Aug-Sept 45   \n",
      "3                                        Fair undamaged  1946-Aug-Sept 45   \n",
      "4                                                  Good       Aug-Sept 45   \n",
      "...                                                 ...               ...   \n",
      "6286                                            A- fair          2.X.1950   \n",
      "6287                                               fair            5-X-50   \n",
      "6288  Harian Men. – Pres. good-undamaged (for missin...         11-X-195b   \n",
      "6289                                               None        56.10.1950   \n",
      "6290                              Restituted to. x fair          20.12.50   \n",
      "\n",
      "                               exit-date  \n",
      "0                              20 Nov 45  \n",
      "1                              20 Nov 45  \n",
      "2                              20 Nov 45  \n",
      "3                              20 Nov 45  \n",
      "4                              20 Nov 45  \n",
      "...                                  ...  \n",
      "6286     1 1. Jan. 1951 to DCR - Germany  \n",
      "6287  15. Jan. 1951 CR- New York-Dorael-  \n",
      "6288         23. Jan. 1951 to CR-To rait  \n",
      "6289                      12. April 1951  \n",
      "6290                       20. Juni 1951  \n",
      "\n",
      "[6112 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from common.event_extraction.helpers import load_data_source\n",
    "\n",
    "RESOURCE_DIR_PATH = os.path.join(\".\", \"resources\")\n",
    "PLOTS_DIR_PATH = os.path.join(\".\", \"plots\")\n",
    "DATA_SOURCE_FILE_PATH = os.path.join(\"..\", \"..\", \"..\", \"data\", \"wccp\", \"wiesbaden-ccp-property-cards-ocr-export-postprocessed-16-11-23.csv\")\n",
    "\n",
    "# We can use multiple columns for parsing in the prompt but only one column is used as a \"main-value\" and is a embedded.\n",
    "EVENT_EXTRACTION_RELEVANT_COLS = [\"history-and-ownership\", \"depot-possessor\", \"depot-number\", \"condition-and-repair-record\", \"arrival-condition\", \"arrival-date\", \"exit-date\"]\n",
    "\n",
    "# Load data source and extract relevant columns\n",
    "data_source = load_data_source(DATA_SOURCE_FILE_PATH, EVENT_EXTRACTION_RELEVANT_COLS)\n",
    "\n",
    "print(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code shows how embeddings can be generated. We assume that only one column of the dataset must be embedded.\n",
    "\n",
    "We generate and cluster embeddings to find good examples for manual annotation as few-shot examples. For the WCCP dataset, this has shown to drastically improve the output quality. However, you may consider different techniques for finding few-shot examples or even use completely different prompting technqiues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.event_extraction.generate_embeddings import generate_embeddings, prepare_df_for_embedding\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "COL_TO_EMBED = \"history-and-ownership\"\n",
    "\n",
    "embeddings = generate_embeddings(\n",
    "    prepare_df_for_embedding(data_source, COL_TO_EMBED)[COL_TO_EMBED], \n",
    "    EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "embedding_cache = data_source[COL_TO_EMBED].to_frame()\n",
    "embedding_cache[\"embedding\"] = embeddings\n",
    "\n",
    "embedding_cache.to_csv(os.path.join(RESOURCE_DIR_PATH, \"embeddings.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can visualize your embedded free-text records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.event_extraction.visualization import visualize_data_source\n",
    "from common.event_extraction.cluster_embeddings import convert_embeddings_to_vstack\n",
    "\n",
    "\n",
    "visualize_data_source(\n",
    "    convert_embeddings_to_vstack(embedding_cache),\n",
    "    os.path.join(PLOTS_DIR_PATH, \"embeddings.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Cluster Embeddings\n",
    "After you executed the code snippet below, you'll need to manually label some free-text records with our set of events. These manually labeled free-text records can then be included in the few-shot prompts in the following steps. The below code snippet produces a JSON file that contains some entries of provenance describing columns. These entries are generated using a clustering algorithm to ensure the best possible dataset coverage. Label those examples manually with the pre-defined event types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Silhouette Average Maximization & Clustering</strong><br>\n",
    "For clustering, we first need to find the best fitting amount of clusters for the KMeans clustering algorithm. For that we use the silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.event_extraction.cluster_embeddings import maximize_silhouette_avg\n",
    "from common.event_extraction.cluster_embeddings import convert_embeddings_to_vstack\n",
    "from common.event_extraction.cluster_embeddings import cluster_embeddings_kmeans\n",
    "\n",
    "# Calculates the best number of clusters for k-means clusterings\n",
    "embeddings_vstack = convert_embeddings_to_vstack(embedding_cache)\n",
    "best_n_clusters = maximize_silhouette_avg(embeddings_vstack)\n",
    "\n",
    "# Runs k-means clustering with the best number of clusters\n",
    "(cluster_labels, cluster_centers) = cluster_embeddings_kmeans(embeddings_vstack, best_n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now also visualize the results using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.event_extraction.visualization import visualize_embedding_clusters\n",
    "\n",
    "# This visualizes the clustering results from above and filters out clusters with less than 10 members\n",
    "visualize_embedding_clusters(\n",
    "    cluster_labels,\n",
    "    embeddings_vstack,\n",
    "    best_n_clusters,\n",
    "    os.path.join(PLOTS_DIR_PATH, \"embedding_clusters.png\"),\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Choosing Representatives</strong><br>\n",
    "Now that we clustered the embeddings, we can filter the representatives and generate the template using the interactive label template generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.event_extraction.cluster_embeddings import choose_representatives\n",
    "\n",
    "choose_representatives(\n",
    "    embeddings=embeddings,\n",
    "    embedded_column_name=COL_TO_EMBED,\n",
    "    relevant_column_names=EVENT_EXTRACTION_RELEVANT_COLS,\n",
    "    data_source=data_source,\n",
    "    cluster_labels=cluster_labels,\n",
    "    cluster_centers=cluster_centers,\n",
    "    write_to_file=True,\n",
    "    output_dir_path=RESOURCE_DIR_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from etltools.cache import JsonCache\n",
    "from common.event_extraction.execute_prompt import execute_prompt\n",
    "\n",
    "PARSING_MODEL = \"gpt-4-turbo-preview\"\n",
    "NUMBER_OF_EXAMPLES = 2\n",
    "\n",
    "# Builds a mapping from the labeled examples to the embeddings\n",
    "with open(\n",
    "    os.path.join(RESOURCE_DIR_PATH, \"event_extraction_labels_template.json\"), \"r\"\n",
    ") as labeled_examples_file:\n",
    "    labeled_examples = json.load(labeled_examples_file)\n",
    "    labeled_examples_df = build_labeled_examples_to_embedding(labeled_examples_file)\n",
    "\n",
    "# Loads prompt from file\n",
    "prompt_txt = open(os.path.join(RESOURCE_DIR_PATH, \"prompt.txt\"), \"r\").read()\n",
    "\n",
    "# Execute prompt for each row in the data source\n",
    "for _, row in data_source.iterrows():\n",
    "    row_vals_to_parse = {key: row[key] in row for key in EVENT_EXTRACTION_RELEVANT_COLS}\n",
    "    execute_prompt(\n",
    "        row_vals_to_parse=row_vals_to_parse,\n",
    "        embedded_col_name=COL_TO_EMBED,\n",
    "        embeddings=embeddings,\n",
    "        labeled_examples=labeled_examples_df,\n",
    "        sys_prompt_txt=prompt_txt,\n",
    "        cache=JsonCache(os.path.join(RESOURCE_DIR_PATH, \"parsing_result_cache.json\")),\n",
    "        model=PARSING_MODEL,\n",
    "        number_of_examples=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-PxPMHYUb-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
