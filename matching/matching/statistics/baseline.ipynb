{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matching.config import Settings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Na√Øve Matching baseline\n",
    "\n",
    "This is a simple baseline using a rule-based approach to matching of cultural assets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/labelled_data.csv\")\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    if row[\"1_collectedIn_name\"] == \"Linzer Sammlung\":\n",
    "        data.at[idx, \"1_createdBy_name\"] = (\n",
    "            f\"{row['1_createdBy_firstName']} {row['1_createdBy_lastName']}\"\n",
    "        )\n",
    "    if row[\"2_collectedIn_name\"] == \"Linzer Sammlung\":\n",
    "        data.at[idx, \"2_createdBy_name\"] = (\n",
    "            f\"{row['2_createdBy_firstName']} {row['2_createdBy_lastName']}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_naive_match(entity1: pd.DataFrame, entity2: pd.DataFrame):\n",
    "    return (\n",
    "        entity1[\"1_physicalDescription\"] == entity2[\"2_physicalDescription\"]\n",
    "        or entity1[\"1_title\"] == entity2[\"2_title\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "for seed in Settings.random_seeds():\n",
    "    traindata, testdata = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "\n",
    "    testdata[\"predictedLabel\"] = np.nan\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, row in testdata.iterrows():\n",
    "        entity1 = row[[col for col in testdata.columns if col.startswith(\"1_\")]]\n",
    "        entity2 = row[[col for col in testdata.columns if col.startswith(\"2_\")]]\n",
    "\n",
    "        label = is_naive_match(entity1, entity2)\n",
    "\n",
    "        predictions.append(1 if label else 0)\n",
    "        labels.append(row[\"label\"])\n",
    "\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(f\"Number of predicted matches: {sum(predictions)}\")\n",
    "    print(f\"Number of actual matches: {sum(labels)}\")\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision_with_outliers = np.mean(precision_list)\n",
    "avg_recall_with_outliers = np.mean(recall_list)\n",
    "\n",
    "print(f\"Average Precision: {avg_precision_with_outliers}\")\n",
    "print(f\"Average Recall: {avg_recall_with_outliers}\")\n",
    "\n",
    "sns.histplot(precision_list)\n",
    "plt.xlabel(\"Precision Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = (\n",
    "    2\n",
    "    * (avg_precision_with_outliers * avg_recall_with_outliers)\n",
    "    / (avg_precision_with_outliers + avg_recall_with_outliers)\n",
    ")\n",
    "\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"F1 Score\",\n",
    "    \"{:0.3f}\".format(f1_score),\n",
    "    \"\\nAverage precision:\",\n",
    "    \"{:0.3f}\".format(avg_precision_with_outliers),\n",
    "    \"\\nAverage recall:\",\n",
    "    \"{:0.3f}\".format(avg_recall_with_outliers),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
